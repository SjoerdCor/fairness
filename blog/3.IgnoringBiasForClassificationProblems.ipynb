{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from aif360.sklearn.preprocessing import ReweighingMeta, Reweighing\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from sklego.preprocessing import InformationFilter\n",
    "\n",
    "from fairness import fairestimator\n",
    "from fairness.blog import utils\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignoring bias for classification problems\n",
    "\n",
    "This notebook is part of a blog series where I investigate bias in AI.\n",
    "\n",
    "1. [Introducing the IgnoringEstimator](https://github.com/SjoerdCor/fairness/blob/main/blog/1.IntroducingTheIgnoringEstimator.ipynb) introduced measures of fairness and showed how naive approaches do not solve them, and on the other hand shows how easily the IgnoringEstimator is implemented and solves them well\n",
    "1. [Dealing with more complex biases](https://github.com/SjoerdCor/fairness/blob/main/blog/2.DealingWithMoreComplexBiases.ipynb) showed how common complex biases are: non-linear, correlated with other attributes and for continuous features, and showed how easy it is to mitigate the disparate treatment with the `IgnoringBiasEstimator`. I also showed how little attention there seems to be for this problem in existing approaches.\n",
    "1. [Ignoring bias for cassification poblems](https://github.com/SjoerdCor/fairness/blob/main/blog/3.IgnoringBiasForClassificationProblems.ipynb) finally shows how to use the Ignoring Estimator for the classic classification problems - since these are more prolific, we can also compare against a wide variety of existing approaches and see the `IgnoringBiasEstimator` does equally well or better both in terms of bias mitigation and accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this imnstallment, I will use the IgnoringBiasClassifier, which eliminates Disparate Treatment for classification problems. Additionally, I will apply a wide variety of other bias mitigation strategies to make a comprehensive comparison, and show that the IgnoringBias does equally well or better both in terms of bias mitigation and accuracy.\n",
    "\n",
    "## Creating the dataset\n",
    "For the last time in this blog, we stick to the employee situation. Image the company now sets out to predict who should be promoted, based on skills. This should only depend on SocialSkills and Education, but in the real world also depends quadratically on age.\n",
    "\n",
    "<img src=\"./figures/DGP_classification.PNG\" title=\"The data generating process for salary for an imaginary company with biases in employee salaries\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_employees_age(size=2500):\n",
    "    X = (pd.DataFrame({'Age': 25 + 40 * np.random.rand(size),\n",
    "                       'Education': 4 + 16 * np.random.rand(size),\n",
    "                       'SocialSkills': np.random.rand(size)\n",
    "                      }\n",
    "                     )\n",
    "        )\n",
    "    return X\n",
    "\n",
    "def eligibility_to_promotion(e):\n",
    "    ''' Real numer -> 0/1 based on binomial distribution via sigmoid'''\n",
    "    prob = scipy.special.expit(e)  # Use logistic function to map real number to probability in range [0, 1]\n",
    "    return np.random.binomial(1, prob) # Turn into yes/no\n",
    "\n",
    "def add_promotion(df):\n",
    "    weights = {'Age': 0,\n",
    "               'Education': 0.02,\n",
    "               'SocialSkills': 0.1\n",
    "              }\n",
    "    error = np.random.normal(-2, 0.2, size=len(df))\n",
    "    df = df.assign(PromotionEligibilitySkill = lambda df: df.mul(weights).sum('columns').add(error),\n",
    "                   PromotionEligibilityTrue = lambda df: (df['PromotionEligibilitySkill']\n",
    "                                                          .add(utils.generate_bias(df['Age'], effect_size=-0.4, power=2))\n",
    "                                                         ),\n",
    "                   PromotionSkill = lambda df: df['PromotionEligibilitySkill'].apply(eligibility_to_promotion),\n",
    "                   PromotionTrue = lambda df: df['PromotionEligibilityTrue'].apply(eligibility_to_promotion),\n",
    "                  )\n",
    "    return df\n",
    "\n",
    "df = generate_employees_age(25000).pipe(add_promotion)\n",
    "PROTECTED_ATTRIBUTE = ['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_90491_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Age</th>        <th class=\"col_heading level0 col1\" >Education</th>        <th class=\"col_heading level0 col2\" >SocialSkills</th>        <th class=\"col_heading level0 col3\" >PromotionEligibilitySkill</th>        <th class=\"col_heading level0 col4\" >PromotionEligibilityTrue</th>        <th class=\"col_heading level0 col5\" >PromotionSkill</th>        <th class=\"col_heading level0 col6\" >PromotionTrue</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_90491_level0_row0\" class=\"row_heading level0 row0\" >6868</th>\n",
       "                        <td id=\"T_90491_row0_col0\" class=\"data row0 col0\" >48.12</td>\n",
       "                        <td id=\"T_90491_row0_col1\" class=\"data row0 col1\" >5.41</td>\n",
       "                        <td id=\"T_90491_row0_col2\" class=\"data row0 col2\" >0.01</td>\n",
       "                        <td id=\"T_90491_row0_col3\" class=\"data row0 col3\" >-1.93</td>\n",
       "                        <td id=\"T_90491_row0_col4\" class=\"data row0 col4\" >-1.52</td>\n",
       "                        <td id=\"T_90491_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "                        <td id=\"T_90491_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row1\" class=\"row_heading level0 row1\" >24016</th>\n",
       "                        <td id=\"T_90491_row1_col0\" class=\"data row1 col0\" >32.33</td>\n",
       "                        <td id=\"T_90491_row1_col1\" class=\"data row1 col1\" >16.42</td>\n",
       "                        <td id=\"T_90491_row1_col2\" class=\"data row1 col2\" >0.32</td>\n",
       "                        <td id=\"T_90491_row1_col3\" class=\"data row1 col3\" >-1.92</td>\n",
       "                        <td id=\"T_90491_row1_col4\" class=\"data row1 col4\" >-2.02</td>\n",
       "                        <td id=\"T_90491_row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "                        <td id=\"T_90491_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row2\" class=\"row_heading level0 row2\" >9668</th>\n",
       "                        <td id=\"T_90491_row2_col0\" class=\"data row2 col0\" >53.25</td>\n",
       "                        <td id=\"T_90491_row2_col1\" class=\"data row2 col1\" >13.57</td>\n",
       "                        <td id=\"T_90491_row2_col2\" class=\"data row2 col2\" >0.90</td>\n",
       "                        <td id=\"T_90491_row2_col3\" class=\"data row2 col3\" >-1.85</td>\n",
       "                        <td id=\"T_90491_row2_col4\" class=\"data row2 col4\" >-1.63</td>\n",
       "                        <td id=\"T_90491_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "                        <td id=\"T_90491_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row3\" class=\"row_heading level0 row3\" >13640</th>\n",
       "                        <td id=\"T_90491_row3_col0\" class=\"data row3 col0\" >45.51</td>\n",
       "                        <td id=\"T_90491_row3_col1\" class=\"data row3 col1\" >7.79</td>\n",
       "                        <td id=\"T_90491_row3_col2\" class=\"data row3 col2\" >0.61</td>\n",
       "                        <td id=\"T_90491_row3_col3\" class=\"data row3 col3\" >-1.65</td>\n",
       "                        <td id=\"T_90491_row3_col4\" class=\"data row3 col4\" >-1.21</td>\n",
       "                        <td id=\"T_90491_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "                        <td id=\"T_90491_row3_col6\" class=\"data row3 col6\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row4\" class=\"row_heading level0 row4\" >14018</th>\n",
       "                        <td id=\"T_90491_row4_col0\" class=\"data row4 col0\" >63.62</td>\n",
       "                        <td id=\"T_90491_row4_col1\" class=\"data row4 col1\" >15.83</td>\n",
       "                        <td id=\"T_90491_row4_col2\" class=\"data row4 col2\" >0.75</td>\n",
       "                        <td id=\"T_90491_row4_col3\" class=\"data row4 col3\" >-1.20</td>\n",
       "                        <td id=\"T_90491_row4_col4\" class=\"data row4 col4\" >-1.91</td>\n",
       "                        <td id=\"T_90491_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "                        <td id=\"T_90491_row4_col6\" class=\"data row4 col6\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row5\" class=\"row_heading level0 row5\" >7488</th>\n",
       "                        <td id=\"T_90491_row5_col0\" class=\"data row5 col0\" >48.97</td>\n",
       "                        <td id=\"T_90491_row5_col1\" class=\"data row5 col1\" >5.16</td>\n",
       "                        <td id=\"T_90491_row5_col2\" class=\"data row5 col2\" >0.47</td>\n",
       "                        <td id=\"T_90491_row5_col3\" class=\"data row5 col3\" >-1.80</td>\n",
       "                        <td id=\"T_90491_row5_col4\" class=\"data row5 col4\" >-1.41</td>\n",
       "                        <td id=\"T_90491_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "                        <td id=\"T_90491_row5_col6\" class=\"data row5 col6\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row6\" class=\"row_heading level0 row6\" >5804</th>\n",
       "                        <td id=\"T_90491_row6_col0\" class=\"data row6 col0\" >40.13</td>\n",
       "                        <td id=\"T_90491_row6_col1\" class=\"data row6 col1\" >18.94</td>\n",
       "                        <td id=\"T_90491_row6_col2\" class=\"data row6 col2\" >0.21</td>\n",
       "                        <td id=\"T_90491_row6_col3\" class=\"data row6 col3\" >-1.52</td>\n",
       "                        <td id=\"T_90491_row6_col4\" class=\"data row6 col4\" >-1.16</td>\n",
       "                        <td id=\"T_90491_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "                        <td id=\"T_90491_row6_col6\" class=\"data row6 col6\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row7\" class=\"row_heading level0 row7\" >12909</th>\n",
       "                        <td id=\"T_90491_row7_col0\" class=\"data row7 col0\" >60.60</td>\n",
       "                        <td id=\"T_90491_row7_col1\" class=\"data row7 col1\" >7.33</td>\n",
       "                        <td id=\"T_90491_row7_col2\" class=\"data row7 col2\" >0.46</td>\n",
       "                        <td id=\"T_90491_row7_col3\" class=\"data row7 col3\" >-1.92</td>\n",
       "                        <td id=\"T_90491_row7_col4\" class=\"data row7 col4\" >-2.28</td>\n",
       "                        <td id=\"T_90491_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "                        <td id=\"T_90491_row7_col6\" class=\"data row7 col6\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row8\" class=\"row_heading level0 row8\" >3386</th>\n",
       "                        <td id=\"T_90491_row8_col0\" class=\"data row8 col0\" >34.74</td>\n",
       "                        <td id=\"T_90491_row8_col1\" class=\"data row8 col1\" >15.03</td>\n",
       "                        <td id=\"T_90491_row8_col2\" class=\"data row8 col2\" >0.97</td>\n",
       "                        <td id=\"T_90491_row8_col3\" class=\"data row8 col3\" >-1.70</td>\n",
       "                        <td id=\"T_90491_row8_col4\" class=\"data row8 col4\" >-1.61</td>\n",
       "                        <td id=\"T_90491_row8_col5\" class=\"data row8 col5\" >0</td>\n",
       "                        <td id=\"T_90491_row8_col6\" class=\"data row8 col6\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_90491_level0_row9\" class=\"row_heading level0 row9\" >9567</th>\n",
       "                        <td id=\"T_90491_row9_col0\" class=\"data row9 col0\" >60.64</td>\n",
       "                        <td id=\"T_90491_row9_col1\" class=\"data row9 col1\" >14.87</td>\n",
       "                        <td id=\"T_90491_row9_col2\" class=\"data row9 col2\" >0.99</td>\n",
       "                        <td id=\"T_90491_row9_col3\" class=\"data row9 col3\" >-1.32</td>\n",
       "                        <td id=\"T_90491_row9_col4\" class=\"data row9 col4\" >-1.69</td>\n",
       "                        <td id=\"T_90491_row9_col5\" class=\"data row9 col5\" >1</td>\n",
       "                        <td id=\"T_90491_row9_col6\" class=\"data row9 col6\" >0</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e387672dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.display_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test,\n",
    " y_train, y_test,\n",
    " y_skill_train, y_skill_test,\n",
    " promotion_prob_skill_train, promotion_prob_skill_test) = sklearn.model_selection.train_test_split(df.filter(['Age', 'Education', 'SocialSkills', 'Experience']),\n",
    "                                                                                                   df['PromotionTrue'],\n",
    "                                                                                                   df['PromotionSkill'],\n",
    "                                                                                                   df['PromotionEligibilitySkill'],\n",
    "                                                                                                   random_state=42\n",
    "                                                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_promotion_prob_by_age(predictions, age, age_group=5, ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    age_grouped = age // age_group * age_group + age_group/2\n",
    "    result = predictions.groupby(age_grouped).agg(['mean', 'sem'])\n",
    "    ax = (result.plot(y='mean', yerr='sem', ax=ax, label=predictions.name, **kwargs))\n",
    "    return ax\n",
    "    \n",
    "ax = plot_promotion_prob_by_age(df['PromotionSkill'], df['Age'])\n",
    "plot_promotion_prob_by_age(df['PromotionTrue'], df['Age'], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the promotions based on skills are independent of age, but in the real world middle-aged people have much higher probability of a promotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the predictions\n",
    "We apply a variety of bias mitigation strategies that work with continuos features:\n",
    "* No bias mitigation strategy, as a baseline\n",
    "* Preprocessing: InformationFilter, as implemented by `scikit-lego`\n",
    "* Preprocessing: Reweighing, as implemented by `aif360`\n",
    "* Inprocessing: AdversarialDebiasing, as implemented by `aif360`\n",
    "* Postprocessing: CalibratedOddsEqualizer, as implemented by `aif360`\n",
    "* Inprocessing: IgnoringBiasClassifier, as defined within this repository\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_to_results(clf, name, predictions=predictions,\n",
    "                               X_train=X_train, y_train=y_train, X_test=X_test,\n",
    "                               protected_attribute=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if protected_attribute: \n",
    "        X_train = X_train.set_index(protected_attribute, append=True)\n",
    "        X_test = X_test.set_index(protected_attribute, append=True)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = utils.predict_series(clf, X=X_test, method='predict_proba')\n",
    "    \n",
    "    if protected_attribute:\n",
    "        y_pred = y_pred.reset_index(protected_attribute, drop=True)\n",
    "    predictions[name] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_kwargs = {'min_samples_leaf': 2, 'random_state': 42}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No bias mitigation\n",
    "As a baseline, let's first calculate the naive approach of fitting a model with the protected attribute as a feature, applying no bias mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**rf_kwargs)\n",
    "add_predictions_to_results(rf, 'NoBiasMitigation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-lego preprocessing: Information Filter\n",
    "Secondly, let's apply the Information Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_information_filter = make_pipeline(InformationFilter(PROTECTED_ATTRIBUTE),\n",
    "                                       RandomForestClassifier(**rf_kwargs),\n",
    "                                      )\n",
    "add_predictions_to_results(clf_information_filter, 'InformationFilter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aif360 Preprocessing: reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_reweighing = ReweighingMeta(RandomForestClassifier(**rf_kwargs), reweigher=Reweighing(PROTECTED_ATTRIBUTE))\n",
    "add_predictions_to_results(clf_reweighing, 'Reweighing', protected_attribute=PROTECTED_ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aif360 Inprocessing: Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf_adv_deb = AdversarialDebiasing(prot_attr=PROTECTED_ATTRIBUTE, adversary_loss_weight=None, random_state=42, classifier_num_hidden_units=64)\n",
    "add_predictions_to_results(clf_adv_deb, 'AdversarialDebiasing', protected_attribute=PROTECTED_ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aif360 Postprocessing: CalibratedOddsEqualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_age_index(series, age_series, dummify=None):\n",
    "    '''\n",
    "    dummify: tuple of low and high to dummify; None if you do not want to dummify\n",
    "    ''' \n",
    "    \n",
    "    res = pd.concat([series, age_series], axis='columns')\n",
    "    if dummify:\n",
    "        res['Age'] = res['Age'].between(*dummify).astype(int)\n",
    "    res = res.set_index('Age', append=True).squeeze()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantaged_age_group = (32.5, 57.5)\n",
    "y_train_with_age = add_age_index(y_train, X_train['Age'], advantaged_age_group)\n",
    "y_test_with_age = add_age_index(y_test, X_test['Age'], advantaged_age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_postproc = PostProcessingMeta(estimator=RandomForestClassifier(**rf_kwargs),\n",
    "                                  postprocessor=CalibratedEqualizedOdds(PROTECTED_ATTRIBUTE, random_state=42),\n",
    "                                  random_state=42)\n",
    "\n",
    "X_test_grouped_age = X_test.assign(Age = lambda df: df['Age'].between(*advantaged_age_group).astype(int))  # CalibratedOddsEqualizer requires exactly two groups\n",
    "add_predictions_to_results(clf_postproc, 'CalibratedOddsEqualizer', y_train=y_train_with_age, protected_attribute=PROTECTED_ATTRIBUTE, X_test=X_test_grouped_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignoring Bias during prediction again solves the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = fairestimator.IgnoringBiasClassifier(RandomForestClassifier(random_state=42, min_samples_leaf=2),\n",
    "                                          ignored_cols=[0], # Ignore the zeroeth column at prediction time -> Age\n",
    "                                          correction_strategy='Logitadditive')\n",
    "\n",
    "add_predictions_to_results(ib, 'IgnoringBias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(predictions)\n",
    "df_bias = df_predictions.sub(promotion_prob_skill_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the different options\n",
    "### Measuring fairness\n",
    "We have applied six bias mitigation strategies, and now we can finally visualize the results. We are looking for two twhings:\n",
    "1. The probability of a promotion should be unbiased, i.e. it should equal for every age group (in this toy dataset skills are independent of age). Just as in [Blog 2](https://github.com/SjoerdCor/fairness/blob/main/blog/2.DealingWithMoreComplexBiases.ipynb), we will use the Mutual Information as a fairness measure.\n",
    "1. The probability of promotion should be well-calibrated, i.e. the average predicted promotion probability should match the average true promotion probability\n",
    "\n",
    "In the plot, we see three groups:\n",
    "\n",
    "* The strongly biased strategy, matching the grey dashed line: the true world biased promotion probabilities\n",
    "  * Applying No Bias Mitigatoin (blue line) propagates the bias\n",
    "* The largely unbiased, but badly calibrated strategies\n",
    "  * AdversialDebiasing (red line)does not exhibit a large bias, but gives everybody a way too low probability of promotion. Perhaps we could improve this with more tweaking, but since it is already very slow and other strategies are succesful out of the box, I decided not to spend more time on this\n",
    "  * Reweighing (green) also is a largely flat line, but also is generally too low\n",
    "* The (mostly) successful strategies, closely following the black dahsed line: the promotion probabilities based purely on skill.\n",
    "  * InformationFilter (in orange) is well-calibrated, but does show some bias against older employees\n",
    "  * Postprocessing with the CalibratedOddsEqualizer (purple) does very well, which is somewhat surprising given that we had to discretize Age. However, I fear it will not scale well to more complex, continuous biases where we do not know well who is (dis)advantaged beforehand.\n",
    "  * IgnoringBias does very well, both on removing bias and calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_promotion_prob_by_age(y_skill_test, X_test['Age'], figsize=(16, 12), ls='--', c='k')\n",
    "plot_promotion_prob_by_age(y_test, X_test['Age'], ax=ax, ls='--', c='grey')\n",
    "\n",
    "for col in df_predictions:\n",
    "    plot_promotion_prob_by_age(df_predictions[col], X_test['Age'], ax=ax)\n",
    "\n",
    "ax.set_ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_disp_treat = (utils.bootstrap(utils.calculate_mutual_information, pd.concat([df_bias, X_test['Age']], axis='columns'), n_neighbors=100)\n",
    "                 .pipe(utils.calculate_bootstrap_confidence_interval)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate the disparate treatment as the mutual information between the age and the bias , which is the difference between the predicted probability of promtion and the skills-based probability of promotion. Indeed, 4 strategies are (mostly) sucessful in removing the bias, the Information Filter is slgihtly less sucessfull and the IgnoringBiasEstimator, again, has the best performance, both in terms of accuracy and bias mitigation, and arguably in ease-of-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_biases(biases: dict, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot fairness metric with uncertainty for multiple mitigation strategies.\n",
    "\n",
    "    biases: fairness metrics, dict of dicts structured \n",
    "        {\"name\": {\"diff_mean\": fairness metric, \"diff_sem\": uncertainty fairness metric}}\n",
    "    **kwargs are passed to the DataFrame plot method\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    df = pd.DataFrame(biases).transpose()\n",
    "    p = ax.barh(y=range(len(df)), width=df[0.5], xerr=(df['Uncertainty_lower'], df['Uncertainty_upper']))\n",
    "    plt.yticks(range(len(df)), df.index)\n",
    "    ax.invert_yaxis()\n",
    "    ax.axvline(0, c='k', ls='--')\n",
    "    ax.bar_label(p, label_type='edge', fmt='%.3f')\n",
    "\n",
    "    ax.set_ylabel('FairnessMethod')\n",
    "    return ax\n",
    "\n",
    "plot_biases(df_disp_treat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring accuracy\n",
    "As a measure of the accuracy of the methods, we use [log loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html), which checks both calibration and accuracy.\n",
    "\n",
    "Importantly, IgnoringBiasEstimator has both the best accuracy and the least disparate treatment. Additionally, it is clear that AdversarialDebiasing does poorly, due to its horrible calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = df_predictions.apply(lambda col: sklearn.metrics.log_loss(y_test, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = accs.plot(kind='barh')\n",
    "plt.bar_label(ax.containers[0], fmt='%.3f', c='white', label_type='center')\n",
    "ax.invert_yaxis()\n",
    "plt.ylabel('Bias mitigation strategy')\n",
    "plt.xlabel('Logloss (lower is better)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this installment, we saw that for classification problems a wide variety of bias mitigation strategies exist, and that the IgnoringBiasClassifier was best in class both in terms of bias mitigation and accuracy. \n",
    "\n",
    "I truly hope the IgnoringBiasEstimator will help mitigate biases in Data Science."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fairness3]",
   "language": "python",
   "name": "conda-env-fairness3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
